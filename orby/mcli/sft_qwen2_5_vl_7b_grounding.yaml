name: verl-finetune-sft-7b

image: whatcanyousee/verl:ngc-cu124-vllm0.8.3-sglang0.4.5-mcore0.12.0-te2.2
integrations:
  - integration_type: git_repo
    git_repo: orby-ai-engineering/verl
    git_branch: rishu/grounding_subtask_full # TODO: Change this according to your experiment!
    pip_install: .
    ssh_clone: true

compute:
  gpus: 64 # Number of GPUs to use (TODO: Change this according to your experiment!)
  cluster: r8z13p2 # TODO: Change this according to your experiment!
  gpu_type: h100_80gb # TODO: Change this according to your experiment!
  node_names: [10.0.148.165, 10.0.151.72, 10.0.151.82, 10.0.152.224, 10.0.153.79, 10.0.154.216, 10.0.155.149, 10.0.155.205, 10.0.156.119, 10.0.158.66, 10.0.158.95]

command: |
  # TODO: Set these variables before running the script.
  export NUM_NODES=8
  export MODEL_NAME=Qwen/Qwen2.5-VL-7B-Instruct
  export PROJECT_NAME=verl_sft_grounding_subtask
  export DATASET_VERSION=os_atlas_uground_subtask
  export EXPERIMENT_NAME=$MODEL_NAME-$DATASET_VERSION-sft
  export DATA_SPLIT=100k # "Set the data split here (example 100k, 5k, 0.05k, etc.)"
  export S3_CHECKPOINT_DIR=s3://orby-osu-va/verl-checkpoints/$PROJECT_NAME/$EXPERIMENT_NAME/$DATA_SPLIT
  export TRAIN_BATCH_SIZE=128
  export MICRO_BATCH_SIZE_PER_GPU=2 
  export FILTER_OVERLONG_PROMPTS_WORKERS=24 # (24 seems to work well for OSAtlas + Uground data)
  export TRAIN_DIR=s3://orby-osu-va/Rishu-Experiment/UGround+OsAtlas+Subtask/full-Uground+OsAtlas+Subtask/train/
  export TEST_DIR=s3://orby-osu-va/Rishu-Experiment/UGround+OsAtlas+Subtask/full-Uground+OsAtlas+Subtask/test/
  export MAX_PROMPT_LENGTH=7100
  
  cd /workspace/verl
  sed -i 's|mirrors.tuna.tsinghua.edu.cn|us.archive.ubuntu.com|g' /etc/apt/sources.list
  apt update
  apt install iproute2 -y
  apt install -y dnsutils
  apt install -y emacs
  apt install -y awscli
  pip install 'urllib3<2'
  pip install s3fs
  pip install parquet-tools
  pip install sgl-kernel
  pip install boto3


  # Set environment variables
  export HYDRA_FULL_ERROR=1
  INTERFACE=$(ip route | grep default | awk '{print $5}' | head -1)
  echo "Using interface: $INTERFACE"
  export GLOO_SOCKET_IFNAME=$INTERFACE
  export HF_HUB_ENABLE_HF_TRANSFER=1

  # Downloads the model
  python3 -c "import transformers; transformers.pipeline(model='$MODEL_NAME', device='cpu')"

  # Install verl lib: https://verl.readthedocs.io/en/latest/start/install.html
  pip3 install -e .[vllm]

  # Set PYTHONPATH for orby.trainer module
  export PYTHONPATH="/workspace/verl:$PYTHONPATH"

  # Calculate local world size (GPUs per node)
  export NPROC_PER_NODE=8 
  
  # Dynamically list all parquet files in S3 directories
  echo "Discovering parquet files in S3..."
  
  
  TRAIN_FILES=$(aws s3 ls $TRAIN_DIR | grep '\.parquet$' | awk -v dir="$TRAIN_DIR" '{print dir $4}' | paste -sd ',' -)
  VAL_FILES=$(aws s3 ls $TEST_DIR | grep '\.parquet$' | awk -v dir="$TEST_DIR" '{print dir $4}' | paste -sd ',' -)
  
  echo "Found train files: $TRAIN_FILES"
  echo "Found val files: $VAL_FILES"
  
  # Run torchrun on each node
  torchrun \
    --nproc_per_node=$NPROC_PER_NODE \
    --nnodes=$NUM_NODES \
    --node_rank=$NODE_RANK \
    --master_addr=$MASTER_ADDR \
    --master_port=${MASTER_PORT:-29500} \
    -m orby.trainer.fsdp_sft_trainer \
    data.train_batch_size=$TRAIN_BATCH_SIZE \
    data.micro_batch_size_per_gpu=$MICRO_BATCH_SIZE_PER_GPU \
    data.train_files="[$TRAIN_FILES]" \
    data.val_files="[$VAL_FILES]" \
    data.prompt_key=prompt \
    data.response_key=response \
    +data.image_key=images \
    +data.filter_overlong_prompts_workers=$FILTER_OVERLONG_PROMPTS_WORKERS \
    +data.max_prompt_length=$MAX_PROMPT_LENGTH \
    +processor.use_fast=true \
    +processor.trust_remote_code=true \
    optim.lr=1e-6 \
    model.partial_pretrain=$MODEL_NAME \
    model.fsdp_config.cpu_offload=true \
    model.enable_gradient_checkpointing=true \
    +model.enable_activation_offload=true \
    model.fsdp_config.offload_params=true \
    +model.fsdp_config.param_offload=true \
    trainer.default_local_dir=$S3_CHECKPOINT_DIR \
    trainer.total_training_steps=null \
    trainer.project_name=$PROJECT_NAME \
    trainer.experiment_name=$EXPERIMENT_NAME \
    trainer.logger=[console,wandb] \
    trainer.default_hdfs_dir=null \
    +trainer.val_interval=25 \
    +trainer.save_interval=50 \
    trainer.total_epochs=1 \
    ulysses_sequence_parallel_size=1 \
    use_remove_padding=false \
    +model.fsdp_config.reshard_after_forward=true \
    +model.use_remove_padding=true \
    model.fsdp_config.wrap_policy.min_num_params=1000000 \
    +model.fsdp_config.optimizer_offload=true


