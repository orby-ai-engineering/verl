name: verl-finetune-sft

image: whatcanyousee/verl:ngc-cu124-vllm0.8.3-sglang0.4.5-mcore0.12.0-te2.2
integrations:
  - integration_type: git_repo
    git_repo: orby-ai-engineering/verl
    git_branch: rishu/full-uground-sft
    pip_install: .
    ssh_clone: true
command: |
  export NUM_NODES=4
  export MODEL_NAME=Qwen/Qwen2.5-VL-7B-Instruct

  cd /workspace/verl
  sed -i 's|mirrors.tuna.tsinghua.edu.cn|us.archive.ubuntu.com|g' /etc/apt/sources.list
  apt update
  apt install iproute2 -y
  apt install -y dnsutils
  apt install -y emacs
  apt install -y awscli
  pip install 'urllib3<2'
  pip install s3fs
  pip install parquet-tools
  pip install sgl-kernel
  pip install boto3

  # Install s5cmd (required by VERL for S3 operations)
  wget https://github.com/peak/s5cmd/releases/download/v2.2.2/s5cmd_2.2.2_Linux-64bit.tar.gz
  tar -xzf s5cmd_2.2.2_Linux-64bit.tar.gz
  mv s5cmd /usr/local/bin/
  chmod +x /usr/local/bin/s5cmd
  rm s5cmd_2.2.2_Linux-64bit.tar.gz

  # Set environment variables
  export HYDRA_FULL_ERROR=1
  INTERFACE=$(ip route | grep default | awk '{print $5}' | head -1)
  echo "Using interface: $INTERFACE"
  export GLOO_SOCKET_IFNAME=$INTERFACE
  export HF_HUB_ENABLE_HF_TRANSFER=1

  # Downloads the model
  python3 -c "import transformers; transformers.pipeline(model='$MODEL_NAME', device='cpu')"

  # Install verl lib: https://verl.readthedocs.io/en/latest/start/install.html
  pip3 install -e .[vllm]

  # Set PYTHONPATH for orby.trainer module
  export PYTHONPATH="/workspace/verl:$PYTHONPATH"

  # Calculate local world size (GPUs per node)
  export NPROC_PER_NODE=8  # 32 total GPUs / 4 nodes = 8 GPUs per node
  
  # Run torchrun on each node
  torchrun \
    --nproc_per_node=$NPROC_PER_NODE \
    --nnodes=4 \
    --node_rank=$NODE_RANK \
    --master_addr=$MASTER_ADDR \
    --master_port=${MASTER_PORT:-29500} \
    -m orby.trainer.fsdp_sft_trainer \
    data.train_batch_size=128 \
    data.micro_batch_size_per_gpu=4 \
    data.train_files=s3://orby-osu-va/Rishu-Uground-test/train/ \
    data.val_files=s3://orby-osu-va/Rishu-Uground-test/test/ \
    data.prompt_key=prompt \
    data.response_key=extra_info \
    +data.image_key=images \
    +processor.use_fast=true \
    +processor.trust_remote_code=true \
    optim.lr=1e-6 \
    data.response_dict_keys=['answer'] \
    model.partial_pretrain=$MODEL_NAME \
    model.fsdp_config.cpu_offload=true \
    model.enable_gradient_checkpointing=true \
    +model.enable_activation_offload=true \
    model.fsdp_config.offload_params=true \
    +model.fsdp_config.param_offload=true \
    trainer.default_local_dir=s3://orby-osu-va/Rishu-Uground-test/100k-checkpoints \
    trainer.total_training_steps=null \
    trainer.project_name=uground-sft \
    trainer.experiment_name=uground-sft-qwen-2.5-7b \
    trainer.logger=[console,wandb] \
    trainer.default_hdfs_dir=null \
    +trainer.val_interval=25 \
    +trainer.save_interval=50 \
    trainer.total_epochs=1 \
    ulysses_sequence_parallel_size=1 \
    use_remove_padding=false \
    +model.fsdp_config.reshard_after_forward=true \
    +model.use_remove_padding=true \
    model.fsdp_config.wrap_policy.min_num_params=1000000 \
    +model.fsdp_config.optimizer_offload=true

compute:
  gpus: 32 # Number of GPUs to use
  cluster: r8z13p2
  gpu_type: h100_80gb
