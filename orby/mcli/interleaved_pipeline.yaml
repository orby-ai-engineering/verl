name: verl-interleaved

image: whatcanyousee/verl:ngc-cu124-vllm0.8.3-sglang0.4.5-mcore0.12.0-te2.2

integrations:
  - integration_type: git_repo
    git_repo: orby-ai-engineering/verl
    git_branch: interleaved
    pip_install: .
    ssh_clone: true

compute:
  gpus: 16 # Number of GPUs to use
  cluster: r8z13p2
  gpu_type: h100_80gb

command: |
  # Set these variables before running the script.
  export EXPERIMENT_NAME="debug_interleaved"
  export PROJECT_NAME=verl_grpo_example_subtask
  export NUM_NODES=2
  export MODEL_NAME=Qwen/Qwen2.5-VL-7B-Instruct
  export INTERLEAVED_STEP_NUM=2

  # This should contain the data for all steps. For example,
  # if INTERLEAVED_STEP_NUM=2, then it should contain:
  # 0/train.parquet, 0/test.parquet, 1/train.parquet, 1/test.parquet
  export INTERLEAVED_DATA_DIR=s3://orby-llm/interleaved/data/debug

  # Set data paths
  export LOCAL_DATA_DIR=$HOME/data
  export LOCAL_MODEL_DIR=$HOME/model
  export S3_CHECKPOINT_DIR=s3://orby-llm/verl-checkpoints/interleaved/$EXPERIMENT_NAME

  # Set SFT parameters
  export SFT_TRAIN_BATCH_SIZE=32
  export INITIAL_SFT_TRAIN_FILES=$LOCAL_DATA_DIR/0/train.parquet
  export INITIAL_SFT_VAL_FILES=$LOCAL_DATA_DIR/0/test.parquet

  # Set GRPO parameters
  export GRPO_TRAIN_BATCH_SIZE=64
  export REWARD_FN=training_reward_func
  export REWARD_FILE=orby/reward/subtask.py
  export COORDINATES_METRIC="gaussian"
  export COORDINATES_GAUSSIAN_SIGMA=2
  export COORDINATES_PIXEL_SQUARE_SIZE=10

  # Set rollout parameters
  export ROLLOUT_OUTPUT_DIR=s3://orby-llm/interleaved/$EXPERIMENT_NAME
  export N_SAMPLES=4
  export TEMPERATURE=0.7
  export ROLLOUT_BATCH_SIZE=1024


  # Init environment
  cd /workspace/verl
  sed -i 's|mirrors.tuna.tsinghua.edu.cn|us.archive.ubuntu.com|g' /etc/apt/sources.list
  apt update
  apt install iproute2 -y
  apt install -y dnsutils
  apt install -y awscli
  pip install 'urllib3<2'
  pip install s3fs
  pip install sgl-kernel
  pip install boto3

  # Set environment variables
  export HYDRA_FULL_ERROR=1
  INTERFACE=$(ip route | grep default | awk '{print $5}' | head -1)
  echo "Using interface: $INTERFACE"
  export GLOO_SOCKET_IFNAME=$INTERFACE
  export HF_HUB_ENABLE_HF_TRANSFER=1
  export CUDA_LAUNCH_BLOCKING=1

  # Download model
  python3 -c "import transformers; transformers.pipeline(model='$MODEL_NAME', device='cpu')"

  # Install verl lib: https://verl.readthedocs.io/en/latest/start/install.html
  pip3 install -e .[vllm]

  # Download merged datasets
  aws s3 cp --no-progress --recursive $INTERLEAVED_DATA_DIR $LOCAL_DATA_DIR

  # Run interleaved pipeline
  bash orby/scripts/interleaved_pipeline.sh
